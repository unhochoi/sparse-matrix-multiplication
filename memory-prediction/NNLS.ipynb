{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>lc</th>\n",
       "      <th>rc</th>\n",
       "      <th>ld</th>\n",
       "      <th>rd</th>\n",
       "      <th>lnnz</th>\n",
       "      <th>rnnz</th>\n",
       "      <th>저장전메모리(작성)</th>\n",
       "      <th>저장후메모리(작성)</th>\n",
       "      <th>좌측, 우측 희소행렬 저장</th>\n",
       "      <th>todense후메모리(작성)</th>\n",
       "      <th>우측 희소행렬 toDense</th>\n",
       "      <th>곱셈후메모리(작성)</th>\n",
       "      <th>곱셈</th>\n",
       "      <th>총메모리합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11636</td>\n",
       "      <td>20031</td>\n",
       "      <td>11259</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>3729601</td>\n",
       "      <td>4988188</td>\n",
       "      <td>10.70</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4.90</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>155935</td>\n",
       "      <td>3626</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>3141609</td>\n",
       "      <td>2848497</td>\n",
       "      <td>9.98</td>\n",
       "      <td>12.4</td>\n",
       "      <td>2.42</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34369</td>\n",
       "      <td>19457</td>\n",
       "      <td>9425</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>2001484</td>\n",
       "      <td>3299434</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17922</td>\n",
       "      <td>160686</td>\n",
       "      <td>714</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.038738</td>\n",
       "      <td>3317532</td>\n",
       "      <td>4447011</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9581</td>\n",
       "      <td>16824</td>\n",
       "      <td>19275</td>\n",
       "      <td>0.047721</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>7693122</td>\n",
       "      <td>2636477</td>\n",
       "      <td>10.50</td>\n",
       "      <td>17.7</td>\n",
       "      <td>7.20</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5579</td>\n",
       "      <td>138770</td>\n",
       "      <td>12555</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>15700344</td>\n",
       "      <td>53942019</td>\n",
       "      <td>10.10</td>\n",
       "      <td>56.3</td>\n",
       "      <td>46.20</td>\n",
       "      <td>69.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>59.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>26061</td>\n",
       "      <td>51521</td>\n",
       "      <td>37087</td>\n",
       "      <td>0.037411</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>50231125</td>\n",
       "      <td>49861395</td>\n",
       "      <td>10.50</td>\n",
       "      <td>77.6</td>\n",
       "      <td>67.10</td>\n",
       "      <td>77.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35625</td>\n",
       "      <td>79414</td>\n",
       "      <td>11287</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.054465</td>\n",
       "      <td>45267635</td>\n",
       "      <td>48824425</td>\n",
       "      <td>10.80</td>\n",
       "      <td>79.1</td>\n",
       "      <td>68.30</td>\n",
       "      <td>79.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>68.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>25865</td>\n",
       "      <td>65104</td>\n",
       "      <td>18847</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.045996</td>\n",
       "      <td>59328892</td>\n",
       "      <td>56438830</td>\n",
       "      <td>10.60</td>\n",
       "      <td>77.3</td>\n",
       "      <td>66.70</td>\n",
       "      <td>86.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>90.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>79.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>37002</td>\n",
       "      <td>90825</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.050066</td>\n",
       "      <td>53772548</td>\n",
       "      <td>62572360</td>\n",
       "      <td>10.80</td>\n",
       "      <td>90.5</td>\n",
       "      <td>79.70</td>\n",
       "      <td>99.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>89.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr      lc     rc        ld        rd      lnnz      rnnz  저장전메모리(작성)  \\\n",
       "0   11636   20031  11259  0.016000  0.022117   3729601   4988188       10.70   \n",
       "1     472  155935   3626  0.042674  0.005037   3141609   2848497        9.98   \n",
       "2   34369   19457   9425  0.002993  0.017991   2001484   3299434       10.80   \n",
       "3   17922  160686    714  0.001152  0.038738   3317532   4447011       10.30   \n",
       "4    9581   16824  19275  0.047721  0.008130   7693122   2636477       10.50   \n",
       "..    ...     ...    ...       ...       ...       ...       ...         ...   \n",
       "95   5579  138770  12555  0.020277  0.030960  15700344  53942019       10.10   \n",
       "96  26061   51521  37087  0.037411  0.026095  50231125  49861395       10.50   \n",
       "97  35625   79414  11287  0.016000  0.054465  45267635  48824425       10.80   \n",
       "98  25865   65104  18847  0.035231  0.045996  59328892  56438830       10.60   \n",
       "99  37002   90825  13760  0.016000  0.050066  53772548  62572360       10.80   \n",
       "\n",
       "    저장후메모리(작성)  좌측, 우측 희소행렬 저장  todense후메모리(작성)  우측 희소행렬 toDense  곱셈후메모리(작성)  \\\n",
       "0         15.6            4.90             15.7              0.1        15.8   \n",
       "1         12.4            2.42             15.2              2.8        15.3   \n",
       "2         14.3            3.50             14.4              0.1        16.2   \n",
       "3         15.0            4.70             15.0              0.0        16.0   \n",
       "4         17.7            7.20             17.8              0.1        17.9   \n",
       "..         ...             ...              ...              ...         ...   \n",
       "95        56.3           46.20             69.3             13.0        69.4   \n",
       "96        77.6           67.10             77.6              0.0        77.6   \n",
       "97        79.1           68.30             79.1              0.0        79.2   \n",
       "98        77.3           66.70             86.5              9.2        90.2   \n",
       "99        90.5           79.70             99.8              9.3        99.9   \n",
       "\n",
       "     곱셈  총메모리합  \n",
       "0   0.1   5.10  \n",
       "1   0.1   5.32  \n",
       "2   1.8   5.40  \n",
       "3   1.0   5.70  \n",
       "4   0.1   7.40  \n",
       "..  ...    ...  \n",
       "95  0.1  59.30  \n",
       "96  0.0  67.10  \n",
       "97  0.1  68.40  \n",
       "98  3.7  79.60  \n",
       "99  0.1  89.10  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import nnls\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('./Non-square-sp-smdm-memory.csv',encoding='euc-kr')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lnnz</th>\n",
       "      <th>lc*rc</th>\n",
       "      <th>lr*rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3729601</td>\n",
       "      <td>225529029</td>\n",
       "      <td>131009724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3141609</td>\n",
       "      <td>565420310</td>\n",
       "      <td>1711472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001484</td>\n",
       "      <td>183382225</td>\n",
       "      <td>323927825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3317532</td>\n",
       "      <td>114729804</td>\n",
       "      <td>12796308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7693122</td>\n",
       "      <td>324282600</td>\n",
       "      <td>184673775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>15700344</td>\n",
       "      <td>1742257350</td>\n",
       "      <td>70044345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>50231125</td>\n",
       "      <td>1910759327</td>\n",
       "      <td>966524307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>45267635</td>\n",
       "      <td>896345818</td>\n",
       "      <td>402099375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>59328892</td>\n",
       "      <td>1227015088</td>\n",
       "      <td>487477655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>53772548</td>\n",
       "      <td>1249752000</td>\n",
       "      <td>509147520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lnnz       lc*rc      lr*rc\n",
       "0    3729601   225529029  131009724\n",
       "1    3141609   565420310    1711472\n",
       "2    2001484   183382225  323927825\n",
       "3    3317532   114729804   12796308\n",
       "4    7693122   324282600  184673775\n",
       "..       ...         ...        ...\n",
       "95  15700344  1742257350   70044345\n",
       "96  50231125  1910759327  966524307\n",
       "97  45267635   896345818  402099375\n",
       "98  59328892  1227015088  487477655\n",
       "99  53772548  1249752000  509147520\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = pd.DataFrame(df['lnnz'], columns=['lnnz'])\n",
    "feature['lc*rc'] = pd.DataFrame(df['lc'] * df['rc'],columns=['lc*rc'])\n",
    "feature['lr*rc'] = pd.DataFrame(df['lr'] * df['rc'],columns=['lr*rc'])\n",
    "target = df['총메모리합']\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  23.749813992142954\n",
      "R^2 :  0.5797748783296288\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "mape = []\n",
    "r2 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    # 훈련 데이터와 테스트 데이터 9:1 분리\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size = 0.1)\n",
    "\n",
    "    # 변형 객체 생성\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "\n",
    "    # 훈련데이터의 모수 분포 저장\n",
    "    minmax_scaler.fit(X_train)\n",
    "\n",
    "    # 훈련 데이터 스케일링\n",
    "    X_train = minmax_scaler.transform(X_train)\n",
    "\n",
    "    # 테스트 데이터의 스케일링\n",
    "    X_test = minmax_scaler.transform(X_test)\n",
    "    \n",
    "    # NNLS(Non-Negative Least Squares)모델 정의 및 X_train 학습\n",
    "    # (모든 가중치가 0 또는 양수값을 가진다.)\n",
    "    np.set_printoptions(precision=8, suppress=True)\n",
    "    nnls_coef, nnls_intercept = nnls(X_train, Y_train, maxiter=1000)\n",
    "\n",
    "    # NNLS를 통해 나온 각 계수 추출\n",
    "    C1=np.array(pd.DataFrame(nnls_coef).iloc[0])\n",
    "    C2=np.array(pd.DataFrame(nnls_coef).iloc[1])\n",
    "    C3=np.array(pd.DataFrame(nnls_coef).iloc[2])\n",
    "\n",
    "    X_train = pd.DataFrame(X_train, columns=['lnnz','lc*rc','lr*rc'])\n",
    "    X_test = pd.DataFrame(X_test, columns=['lnnz','lc*rc','lr*rc'])\n",
    "    \n",
    "    # X_test 예측\n",
    "    nnls_Y_pred = C1*X_test['lnnz'] + C2*X_test['lc*rc'] + C3*X_test['lr*rc']\n",
    "    \n",
    "    # 모델의 weight(가중치)와 bias(절편) 출력\n",
    "    #print(\"nnls_coef : \",nnls_coef)\n",
    "    #print(\"\\nnnls_intercept : \",nnls_intercept)\n",
    "\n",
    "#     # nnls metric\n",
    "#     print(\"\\nMAPE : \", mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "#     print(\"R^2 : \", r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "    #print(nnls_coef)\n",
    "\n",
    "    mape.append(mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "    r2.append(r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "print(\"MAPE : \", sum(mape)/len(mape) )\n",
    "print(\"R^2 : \", sum(r2)/len(r2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.0000007  0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000071 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.00000001]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.0000007  0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000071 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.00000001]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.00000001]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.00000001]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.00000001]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000072 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.00000001]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.00000001]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.0000007  0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000063 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.00000001]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000064 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.00000063 0.00000001 0.        ]\n",
      "[0.00000063 0.00000001 0.00000001]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000065 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "[0.00000068 0.00000001 0.        ]\n",
      "[0.0000007  0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.0000007  0.00000001 0.        ]\n",
      "[0.00000066 0.00000001 0.        ]\n",
      "[0.00000067 0.00000001 0.        ]\n",
      "[0.00000069 0.00000001 0.        ]\n",
      "MAPE :  22.64874329584864\n",
      "R^2 :  0.603804203700318\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "mape = []\n",
    "r2 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    # 훈련 데이터와 테스트 데이터 9:1 분리\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size = 0.1)\n",
    "\n",
    "    # NNLS(Non-Negative Least Squares)모델 정의 및 X_train 학습\n",
    "    # (모든 가중치가 0 또는 양수값을 가진다.)\n",
    "    np.set_printoptions(precision=8, suppress=True)\n",
    "    nnls_coef, nnls_intercept = nnls(X_train.to_numpy(), Y_train.to_numpy(), maxiter=1000)\n",
    "\n",
    "    # NNLS를 통해 나온 각 계수 추출\n",
    "    C1=np.array(pd.DataFrame(nnls_coef).iloc[0])\n",
    "    C2=np.array(pd.DataFrame(nnls_coef).iloc[1])\n",
    "    C3=np.array(pd.DataFrame(nnls_coef).iloc[2])\n",
    "\n",
    "    # X_test 예측\n",
    "    nnls_Y_pred = C1*X_test['lnnz'] + C2*X_test['lc*rc'] + C3*X_test['lr*rc']\n",
    "\n",
    "    # 모델의 weight(가중치)와 bias(절편) 출력\n",
    "    #print(\"nnls_coef : \",nnls_coef)\n",
    "    #print(\"\\nnnls_intercept : \",nnls_intercept)\n",
    "\n",
    "#     # nnls metric\n",
    "#     print(\"\\nMAPE : \", mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "#     print(\"R^2 : \", r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "#     print(nnls_coef)\n",
    "\n",
    "    mape.append(mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "    r2.append(r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "print(\"MAPE : \", sum(mape)/len(mape) )\n",
    "print(\"R^2 : \", sum(r2)/len(r2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0000244  0.0000109  0.0000764  0.        29.9441178  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000289  0.0000061  0.0000687  8.9730252 18.542193   0.0000006\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000245  0.0000077  0.0000831  5.078137  19.9361471  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000258  0.0000128  0.0000819  2.8944823 22.2377062  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000254  0.0000076  0.0000489  1.0452399 40.852684   0.0000007\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000218  0.0000118  0.0000791  0.        17.0576003  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000213  0.0000104  0.0000815  0.        26.4317844  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000169  0.000008   0.0000732  3.3711166 63.3951127  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000266  0.0000082  0.000095   0.        22.1743263  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000181  0.0000028  0.0000828  0.        43.6669396  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[0.0000296 0.0000098 0.0000831 0.        4.4056284 0.0000006 0.0000006]\n",
      "\n",
      "[ 0.0000262  0.0000069  0.0000613 17.1730489 25.147664   0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000234  0.000004   0.000072   0.        35.0981134  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000188  0.000007   0.0001029  9.2900243 21.578368   0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000278  0.0000054  0.0000482 10.062474  35.493996   0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000026   0.0000143  0.0000755  0.        27.4346781  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[0.0000266 0.0000194 0.0000695 0.        4.0384832 0.0000006 0.0000006]\n",
      "\n",
      "[ 0.0000309  0.0000019  0.0000766 21.9793892 34.3912849  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000241  0.0000053  0.0000559 16.5226581 50.9335917  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000022   0.000013   0.0000866  0.6769696 36.9895887  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000267  0.0000062  0.0000702 11.0260575 51.7866917  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000341  0.0000021  0.0000273 32.8803598 25.1026669  0.0000006\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000244  0.0000101  0.0000851  0.        27.2571953  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000302  0.0000063  0.0000482 18.9362657 29.2475064  0.0000006\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000236  0.0000144  0.0000703  0.        35.0884197  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000281  0.0000068  0.0000664 23.4251246 27.1629529  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000265  0.0000066  0.000066   0.        22.6457812  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000026   0.0000107  0.0000707  0.        11.7759254  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[0.0000323 0.0000124 0.0000804 2.3381862 7.251216  0.0000006 0.0000006]\n",
      "\n",
      "[ 0.0000213  0.0000072  0.0000761  0.        42.2856319  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000022   0.0000089  0.0000776  0.        35.2864624  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000312  0.0000127  0.0000686  7.6203245 25.7566759  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000283  0.0000048  0.0000794 25.2637264 31.8237296  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000027   0.0000083  0.0000682  3.2279808 36.6047835  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000271  0.0000067  0.0000921  0.        34.8904221  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000251  0.0000106  0.0000477 18.7359958 20.4931972  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000248  0.0000113  0.0000806  0.        19.7490686  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000231  0.0000073  0.0000775  0.        45.2186914  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000208  0.0000071  0.0000776  0.        31.8369384  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000288  0.000011   0.0000676  1.5656028 46.7406265  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000025   0.0000121  0.0000716  0.        37.0454295  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000173  0.000005   0.0000718  4.5248089 48.2063449  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000203  0.0000063  0.00005   16.9923739 42.7108439  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000018   0.0000056  0.0000757 12.3712776 22.596686   0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000221  0.0000108  0.0000828  0.        19.6056882  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000301  0.0000027  0.0000726 12.7668913 37.0358277  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000195  0.0000124  0.0000811 21.1576627 12.0894861  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000243  0.0000054  0.0000806 21.674366  12.2448442  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000241  0.0000096  0.0000936  0.        29.6686191  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000269  0.0000063  0.0000462 10.6023023 35.8728033  0.0000007\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.000019   0.0000194  0.0000854  0.        29.6173036  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000277  0.0000107  0.0000783  0.        28.4240538  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000237  0.000009   0.0000865  8.8485979 29.1381544  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000252  0.0000077  0.0000416 12.8293819 30.7795129  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000193  0.0000083  0.0000883  0.        45.2278165  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000104  0.0000115  0.0000728  0.        46.1699401  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000019   0.0000083  0.0000775  8.9492683 25.4591214  0.0000007\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000255  0.0000065  0.0000613  7.5734901 34.0562313  0.0000007\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000302  0.000008   0.000072   8.6543886 23.78495    0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.00002    0.000014   0.0000885 11.4576115 24.7714868  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000215  0.0000085  0.0000724  1.821412  42.8689868  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000326  0.0000093  0.0000731  2.9276639 29.3503663  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000198  0.0000126  0.0000831  0.        27.2449795  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000219  0.0000062  0.0000699  1.9684008 48.6094068  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000225  0.0000087  0.0000636  0.        30.201116   0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000314  0.0000095  0.0000682  9.0134124 35.6900518  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000256  0.000005   0.0000552 24.5387546 23.2196172  0.0000006\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000198  0.0000055  0.0000786  4.1170245 45.2408864  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000021   0.0000076  0.0000778  0.1886589 43.9572773  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000263  0.0000098  0.0000891  0.        26.7075612  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000236  0.0000022  0.0000599  9.6718141 27.8943927  0.0000007\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000256  0.0000096  0.0000964  0.        18.8207442  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000017   0.0000089  0.0000723  0.        49.8690566  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000251  0.0000097  0.0000492  8.1653459 47.8746387  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000216  0.0000094  0.0000867  0.        38.4137647  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000032   0.0000056  0.0000465 29.9167355 31.9826478  0.0000006\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000313  0.0000017  0.0000575  3.9547089 33.9465462  0.0000006\n",
      "  0.0000007]\n",
      "\n",
      "[ 0.0000228  0.0000088  0.0000836  0.        25.3943531  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000227  0.000013   0.0001007  8.6180989 36.6465603  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000028   0.0000041  0.0000559 10.1899445 43.7776212  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000023   0.0000098  0.0001064  4.7076371 11.3379541  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000238  0.0000078  0.0000758  0.        40.9168503  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000298  0.0000052  0.0000943  0.        35.3957606  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000025   0.0000098  0.0000786  0.        37.1441605  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000222  0.0000085  0.0000981 10.9492223 26.2155667  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.000036   0.0000098  0.0000777  0.        28.1207549  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000269  0.0000067  0.0000782  0.        31.9926318  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000268  0.0000089  0.0000728  0.        22.7859463  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000216  0.000009   0.0000846  0.        43.0046647  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000276  0.0000068  0.0000793  4.9418361 27.7515119  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000244  0.0000134  0.0000661  0.        19.197012   0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000229  0.000004   0.00008    0.        39.3601436  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000238  0.0000114  0.0000643  0.        39.3042411  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000265  0.0000122  0.0000805  0.        30.9919105  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000222  0.0000095  0.0000844 10.7295638 29.8328927  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000224  0.0000126  0.00008    0.        31.3052004  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000278  0.0000068  0.0000685  0.        36.2188046  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000216  0.0000113  0.0001081  4.9414245 45.3419755  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000182  0.0000099  0.0000934  0.        51.0806343  0.0000007\n",
      "  0.0000006]\n",
      "\n",
      "[ 0.0000229  0.0000143  0.0001113  0.        31.3807113  0.0000006\n",
      "  0.0000006]\n",
      "\n",
      "MAPE :  15.46731426392299\n",
      "R^2 :  0.8456834516221545\n"
     ]
    }
   ],
   "source": [
    "# feature, target 값 정의\n",
    "feature = df[['lr','lc','rc','ld','rd','lnnz','rnnz']]\n",
    "feature = feature.astype({'lr': 'int','lc': 'int','rc': 'int','lnnz': 'int','rnnz': 'int'})\n",
    "target = df['총메모리합']\n",
    "\n",
    "epoch = 100\n",
    "mape = []\n",
    "r2 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    # 훈련 데이터와 테스트 데이터 분리\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size = 0.1)\n",
    "\n",
    "    # NNLS(Non-Negative Least Squares)회귀모델 정의 및 훈련데이터로 학습\n",
    "    # (모든 가중치가 0 또는 양수값을 가진다.)\n",
    "    np.set_printoptions(precision=7, suppress=True)\n",
    "    nnls_coef, nnls_intercept =nnls(X_train.to_numpy(), Y_train.to_numpy(), maxiter=1000)\n",
    "\n",
    "    # NNLS를 통해 나온 각 weight 추출\n",
    "    C1=np.array(pd.DataFrame(nnls_coef).iloc[0])\n",
    "    C2=np.array(pd.DataFrame(nnls_coef).iloc[1])\n",
    "    C3=np.array(pd.DataFrame(nnls_coef).iloc[2])\n",
    "    C4=np.array(pd.DataFrame(nnls_coef).iloc[3])\n",
    "    C5=np.array(pd.DataFrame(nnls_coef).iloc[4])\n",
    "    C6=np.array(pd.DataFrame(nnls_coef).iloc[5])\n",
    "    C7=np.array(pd.DataFrame(nnls_coef).iloc[6])\n",
    "\n",
    "    # 테스트 데이터 예측값 도출\n",
    "    nnls_Y_pred = C1*X_test['lr']+C2*X_test['lc']+C3*X_test['rc']+C4*X_test['ld']+C5*X_test['rd']+C6*X_test['lnnz']+C7*X_test['rnnz']\n",
    "\n",
    "    # 모델의 weight(가중치)와 bias(절편) 출력\n",
    "    #print(\"nnls_coef : \",nnls_coef)\n",
    "    #print(\"\\nnnls_intercept : \",nnls_intercept)\n",
    "\n",
    "    # nnls metric\n",
    "    #print(\"\\nMAPE : \", mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "    #print(\"R^2 : \", r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "    print(str(nnls_coef) + \"\\n\")    \n",
    "    \n",
    "    mape.append(mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "    r2.append(r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "print(\"MAPE : \", sum(mape)/len(mape) )\n",
    "print(\"R^2 : \", sum(r2)/len(r2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000068]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000074 0.0000007 ]\n",
      "\n",
      "[0.00000073 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000069]\n",
      "\n",
      "[0.00000073 0.00000069]\n",
      "\n",
      "[0.00000073 0.0000007 ]\n",
      "\n",
      "[0.00000074 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000074 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000069]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000071 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000073 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.0000007  0.00000072]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000074 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000071 0.0000007 ]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000069]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000069]\n",
      "\n",
      "[0.00000074 0.00000069]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000071 0.00000072]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000071 0.0000007 ]\n",
      "\n",
      "[0.00000073 0.00000069]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000071 0.00000073]\n",
      "\n",
      "[0.00000072 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000071 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000073 0.00000069]\n",
      "\n",
      "[0.00000072 0.00000072]\n",
      "\n",
      "[0.00000073 0.0000007 ]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "[0.00000072 0.00000071]\n",
      "\n",
      "MAPE :  15.05191993322981\n",
      "R^2 :  0.8382022474399128\n"
     ]
    }
   ],
   "source": [
    "# feature, target 값 정의\n",
    "feature = df[['lnnz','rnnz']]\n",
    "feature = feature.astype({'lnnz': 'int','rnnz': 'int'})\n",
    "target = df['총메모리합']\n",
    "\n",
    "epoch = 100\n",
    "mape = []\n",
    "r2 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    # 훈련 데이터와 테스트 데이터 분리\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size = 0.1)\n",
    "\n",
    "    # NNLS(Non-Negative Least Squares)회귀모델 정의 및 훈련데이터로 학습\n",
    "    # (모든 가중치가 0 또는 양수값을 가진다.)\n",
    "    np.set_printoptions(precision=8, suppress=True)\n",
    "    nnls_coef, nnls_intercept =nnls(X_train.to_numpy(), Y_train.to_numpy(), maxiter=1000)\n",
    "\n",
    "    # NNLS를 통해 나온 각 weight 추출\n",
    "    C1=np.array(pd.DataFrame(nnls_coef).iloc[0])\n",
    "    C2=np.array(pd.DataFrame(nnls_coef).iloc[1])\n",
    "\n",
    "\n",
    "    # 테스트 데이터 예측값 도출\n",
    "    nnls_Y_pred = C1*X_test['lnnz']+C2*X_test['rnnz']\n",
    "\n",
    "    # 모델의 weight(가중치)와 bias(절편) 출력\n",
    "    #print(\"nnls_coef : \",nnls_coef)\n",
    "    #print(\"\\nnnls_intercept : \",nnls_intercept)\n",
    "\n",
    "    # nnls metric\n",
    "    #print(\"\\nMAPE : \", mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "    #print(\"R^2 : \", r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "    print(str(nnls_coef) + \"\\n\")    \n",
    "    \n",
    "    mape.append(mean_absolute_percentage_error(Y_test,nnls_Y_pred))\n",
    "    r2.append(r2_score(Y_test, nnls_Y_pred))\n",
    "\n",
    "print(\"MAPE : \", sum(mape)/len(mape) )\n",
    "print(\"R^2 : \", sum(r2)/len(r2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
