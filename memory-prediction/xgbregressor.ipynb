{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c089fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>lc</th>\n",
       "      <th>rc</th>\n",
       "      <th>ld</th>\n",
       "      <th>rd</th>\n",
       "      <th>lnnz</th>\n",
       "      <th>rnnz</th>\n",
       "      <th>저장전메모리(작성)</th>\n",
       "      <th>저장후메모리(작성)</th>\n",
       "      <th>좌측, 우측 희소행렬 저장</th>\n",
       "      <th>todense후메모리(작성)</th>\n",
       "      <th>우측 희소행렬 toDense</th>\n",
       "      <th>곱셈후메모리(작성)</th>\n",
       "      <th>곱셈</th>\n",
       "      <th>총메모리합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11636</td>\n",
       "      <td>20031</td>\n",
       "      <td>11259</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>3729601</td>\n",
       "      <td>4988188</td>\n",
       "      <td>10.70</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4.90</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>155935</td>\n",
       "      <td>3626</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>3141609</td>\n",
       "      <td>2848497</td>\n",
       "      <td>9.98</td>\n",
       "      <td>12.4</td>\n",
       "      <td>2.42</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34369</td>\n",
       "      <td>19457</td>\n",
       "      <td>9425</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>2001484</td>\n",
       "      <td>3299434</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17922</td>\n",
       "      <td>160686</td>\n",
       "      <td>714</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.038738</td>\n",
       "      <td>3317532</td>\n",
       "      <td>4447011</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9581</td>\n",
       "      <td>16824</td>\n",
       "      <td>19275</td>\n",
       "      <td>0.047721</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>7693122</td>\n",
       "      <td>2636477</td>\n",
       "      <td>10.50</td>\n",
       "      <td>17.7</td>\n",
       "      <td>7.20</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5579</td>\n",
       "      <td>138770</td>\n",
       "      <td>12555</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>15700344</td>\n",
       "      <td>53942019</td>\n",
       "      <td>10.10</td>\n",
       "      <td>56.3</td>\n",
       "      <td>46.20</td>\n",
       "      <td>69.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>59.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>26061</td>\n",
       "      <td>51521</td>\n",
       "      <td>37087</td>\n",
       "      <td>0.037411</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>50231125</td>\n",
       "      <td>49861395</td>\n",
       "      <td>10.50</td>\n",
       "      <td>77.6</td>\n",
       "      <td>67.10</td>\n",
       "      <td>77.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35625</td>\n",
       "      <td>79414</td>\n",
       "      <td>11287</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.054465</td>\n",
       "      <td>45267635</td>\n",
       "      <td>48824425</td>\n",
       "      <td>10.80</td>\n",
       "      <td>79.1</td>\n",
       "      <td>68.30</td>\n",
       "      <td>79.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>68.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>25865</td>\n",
       "      <td>65104</td>\n",
       "      <td>18847</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.045996</td>\n",
       "      <td>59328892</td>\n",
       "      <td>56438830</td>\n",
       "      <td>10.60</td>\n",
       "      <td>77.3</td>\n",
       "      <td>66.70</td>\n",
       "      <td>86.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>90.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>79.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>37002</td>\n",
       "      <td>90825</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.050066</td>\n",
       "      <td>53772548</td>\n",
       "      <td>62572360</td>\n",
       "      <td>10.80</td>\n",
       "      <td>90.5</td>\n",
       "      <td>79.70</td>\n",
       "      <td>99.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>99.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>89.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr      lc     rc        ld        rd      lnnz      rnnz  저장전메모리(작성)  \\\n",
       "0   11636   20031  11259  0.016000  0.022117   3729601   4988188       10.70   \n",
       "1     472  155935   3626  0.042674  0.005037   3141609   2848497        9.98   \n",
       "2   34369   19457   9425  0.002993  0.017991   2001484   3299434       10.80   \n",
       "3   17922  160686    714  0.001152  0.038738   3317532   4447011       10.30   \n",
       "4    9581   16824  19275  0.047721  0.008130   7693122   2636477       10.50   \n",
       "..    ...     ...    ...       ...       ...       ...       ...         ...   \n",
       "95   5579  138770  12555  0.020277  0.030960  15700344  53942019       10.10   \n",
       "96  26061   51521  37087  0.037411  0.026095  50231125  49861395       10.50   \n",
       "97  35625   79414  11287  0.016000  0.054465  45267635  48824425       10.80   \n",
       "98  25865   65104  18847  0.035231  0.045996  59328892  56438830       10.60   \n",
       "99  37002   90825  13760  0.016000  0.050066  53772548  62572360       10.80   \n",
       "\n",
       "    저장후메모리(작성)  좌측, 우측 희소행렬 저장  todense후메모리(작성)  우측 희소행렬 toDense  곱셈후메모리(작성)  \\\n",
       "0         15.6            4.90             15.7              0.1        15.8   \n",
       "1         12.4            2.42             15.2              2.8        15.3   \n",
       "2         14.3            3.50             14.4              0.1        16.2   \n",
       "3         15.0            4.70             15.0              0.0        16.0   \n",
       "4         17.7            7.20             17.8              0.1        17.9   \n",
       "..         ...             ...              ...              ...         ...   \n",
       "95        56.3           46.20             69.3             13.0        69.4   \n",
       "96        77.6           67.10             77.6              0.0        77.6   \n",
       "97        79.1           68.30             79.1              0.0        79.2   \n",
       "98        77.3           66.70             86.5              9.2        90.2   \n",
       "99        90.5           79.70             99.8              9.3        99.9   \n",
       "\n",
       "     곱셈  총메모리합  \n",
       "0   0.1   5.10  \n",
       "1   0.1   5.32  \n",
       "2   1.8   5.40  \n",
       "3   1.0   5.70  \n",
       "4   0.1   7.40  \n",
       "..  ...    ...  \n",
       "95  0.1  59.30  \n",
       "96  0.0  67.10  \n",
       "97  0.1  68.40  \n",
       "98  3.7  79.60  \n",
       "99  0.1  89.10  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import nnls\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "df = pd.read_csv('./Non-square-sp-smdm-memory.csv',encoding='euc-kr')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed217859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature\n",
    "feature = df[['lr','lc','rc','ld','rd','lnnz','rnnz']] \n",
    "target = df['총메모리합']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c259b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 9:1 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ee77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 탐색 대상 함수 (XGBRegressor)\n",
    "def XGB(\n",
    "max_depth,\n",
    "learning_rate, \n",
    "n_estimators, \n",
    "min_child_weight, \n",
    "subsample,\n",
    "_lambda,\n",
    "#gamma ,\n",
    "#colsample_bytree, \n",
    "#_alpha,\n",
    "silent=True, \n",
    "n_jobs=-1):\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = xgb.XGBRegressor( \n",
    "objective = 'reg:squarederror',\n",
    "max_depth=int(max_depth),\n",
    "learning_rate=learning_rate,\n",
    "n_estimators=int(n_estimators),\n",
    "min_child_weight=min_child_weight,\n",
    "subsample=subsample,\n",
    "reg_lambda=_lambda,        \n",
    "#gamma=gamma,\n",
    "#colsample_bytree=colsample_bytree, \n",
    "#reg_alpha=_alpha\n",
    "n_jobs=n_jobs        \n",
    "                              )\n",
    "    \n",
    "    # bayesian optimization을 통해 파라미터를 받아\n",
    "    # Train을 Train + Validation으로 나눠 cross-validation 성능 확인\n",
    "    kfold = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "\n",
    "    # cross-validation 평균 성능 성능 확인\n",
    "    score = cross_val_score(model,\n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=kfold,\n",
    "                            scoring=make_scorer(custom_scoring,greater_is_better=False),\n",
    "                            n_jobs=-1\n",
    "                           ).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13def06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Metric\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "def custom_scoring(real, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(real, pred))\n",
    "    r2 = r2_score(real, pred)\n",
    "    mape = mean_absolute_percentage_error(real, pred)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8112f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  _lambda  | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-15.82   \u001b[0m | \u001b[0m 0.4753  \u001b[0m | \u001b[0m 0.2189  \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 0.3721  \u001b[0m | \u001b[0m 64.68   \u001b[0m | \u001b[0m 0.5462  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-14.63   \u001b[0m | \u001b[95m 0.2676  \u001b[0m | \u001b[95m 0.1102  \u001b[0m | \u001b[95m 13.59   \u001b[0m | \u001b[95m 0.5849  \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 0.8426  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-14.75   \u001b[0m | \u001b[0m 0.2233  \u001b[0m | \u001b[0m 0.1116  \u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 0.4265  \u001b[0m | \u001b[0m 91.26   \u001b[0m | \u001b[0m 0.7918  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-15.1    \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 0.2067  \u001b[0m | \u001b[0m 12.15   \u001b[0m | \u001b[0m 0.9256  \u001b[0m | \u001b[0m 94.65   \u001b[0m | \u001b[0m 0.8862  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-37.7    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 12.02   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 91.5    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-14.19   \u001b[0m | \u001b[95m 0.3258  \u001b[0m | \u001b[95m 0.1503  \u001b[0m | \u001b[95m 14.26   \u001b[0m | \u001b[95m 0.3906  \u001b[0m | \u001b[95m 91.96   \u001b[0m | \u001b[95m 0.7704  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-16.18   \u001b[0m | \u001b[0m 0.5268  \u001b[0m | \u001b[0m 0.2203  \u001b[0m | \u001b[0m 13.87   \u001b[0m | \u001b[0m 0.4454  \u001b[0m | \u001b[0m 93.26   \u001b[0m | \u001b[0m 0.7482  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-17.58   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 14.18   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 91.8    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.4401  \u001b[0m | \u001b[0m 0.06832 \u001b[0m | \u001b[0m 12.81   \u001b[0m | \u001b[0m 0.1098  \u001b[0m | \u001b[0m 95.57   \u001b[0m | \u001b[0m 0.8364  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m 0.3655  \u001b[0m | \u001b[0m 0.2762  \u001b[0m | \u001b[0m 13.35   \u001b[0m | \u001b[0m 0.8662  \u001b[0m | \u001b[0m 94.96   \u001b[0m | \u001b[0m 0.9384  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-17.96   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 96.01   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-16.13   \u001b[0m | \u001b[0m 0.1277  \u001b[0m | \u001b[0m 0.2258  \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 0.1388  \u001b[0m | \u001b[0m 94.65   \u001b[0m | \u001b[0m 0.6583  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-14.79   \u001b[0m | \u001b[0m 0.5094  \u001b[0m | \u001b[0m 0.09745 \u001b[0m | \u001b[0m 14.12   \u001b[0m | \u001b[0m 0.1425  \u001b[0m | \u001b[0m 96.71   \u001b[0m | \u001b[0m 0.7688  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-38.08   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 95.64   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-14.25   \u001b[0m | \u001b[0m 0.2284  \u001b[0m | \u001b[0m 0.03054 \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 0.1989  \u001b[0m | \u001b[0m 96.85   \u001b[0m | \u001b[0m 0.6796  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-16.28   \u001b[0m | \u001b[0m 0.2503  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 14.44   \u001b[0m | \u001b[0m 0.1293  \u001b[0m | \u001b[0m 97.59   \u001b[0m | \u001b[0m 0.7423  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-16.57   \u001b[0m | \u001b[0m 0.1645  \u001b[0m | \u001b[0m 0.2045  \u001b[0m | \u001b[0m 13.77   \u001b[0m | \u001b[0m 0.9887  \u001b[0m | \u001b[0m 96.86   \u001b[0m | \u001b[0m 0.9379  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-17.47   \u001b[0m | \u001b[0m 0.8585  \u001b[0m | \u001b[0m 0.1962  \u001b[0m | \u001b[0m 13.76   \u001b[0m | \u001b[0m 0.3783  \u001b[0m | \u001b[0m 97.37   \u001b[0m | \u001b[0m 0.7647  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-38.81   \u001b[0m | \u001b[0m 0.6164  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 13.84   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 92.02   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-17.47   \u001b[0m | \u001b[0m 0.1833  \u001b[0m | \u001b[0m 0.2982  \u001b[0m | \u001b[0m 13.85   \u001b[0m | \u001b[0m 0.2254  \u001b[0m | \u001b[0m 79.57   \u001b[0m | \u001b[0m 0.5583  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-15.63   \u001b[0m | \u001b[0m 0.2403  \u001b[0m | \u001b[0m 0.02925 \u001b[0m | \u001b[0m 15.66   \u001b[0m | \u001b[0m 0.1884  \u001b[0m | \u001b[0m 81.17   \u001b[0m | \u001b[0m 0.8203  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-14.86   \u001b[0m | \u001b[0m 0.4651  \u001b[0m | \u001b[0m 0.2226  \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 0.9917  \u001b[0m | \u001b[0m 135.5   \u001b[0m | \u001b[0m 0.6249  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-15.04   \u001b[0m | \u001b[0m 0.113   \u001b[0m | \u001b[0m 0.1958  \u001b[0m | \u001b[0m 12.07   \u001b[0m | \u001b[0m 0.8992  \u001b[0m | \u001b[0m 143.9   \u001b[0m | \u001b[0m 0.6135  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-17.01   \u001b[0m | \u001b[0m 0.148   \u001b[0m | \u001b[0m 0.1681  \u001b[0m | \u001b[0m 14.12   \u001b[0m | \u001b[0m 0.1301  \u001b[0m | \u001b[0m 78.17   \u001b[0m | \u001b[0m 0.7539  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-15.25   \u001b[0m | \u001b[0m 0.5351  \u001b[0m | \u001b[0m 0.2305  \u001b[0m | \u001b[0m 15.24   \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 0.856   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-20.2    \u001b[0m | \u001b[0m 0.4406  \u001b[0m | \u001b[0m 0.03399 \u001b[0m | \u001b[0m 14.03   \u001b[0m | \u001b[0m 0.482   \u001b[0m | \u001b[0m 52.9    \u001b[0m | \u001b[0m 0.578   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-15.01   \u001b[0m | \u001b[0m 0.7341  \u001b[0m | \u001b[0m 0.04881 \u001b[0m | \u001b[0m 15.19   \u001b[0m | \u001b[0m 0.6725  \u001b[0m | \u001b[0m 111.7   \u001b[0m | \u001b[0m 0.7667  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-17.24   \u001b[0m | \u001b[0m 0.8382  \u001b[0m | \u001b[0m 0.2583  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 0.8352  \u001b[0m | \u001b[0m 149.5   \u001b[0m | \u001b[0m 0.8486  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-16.2    \u001b[0m | \u001b[0m 0.1095  \u001b[0m | \u001b[0m 0.2247  \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 0.6965  \u001b[0m | \u001b[0m 144.9   \u001b[0m | \u001b[0m 0.5775  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.09564 \u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 0.2407  \u001b[0m | \u001b[0m 115.1   \u001b[0m | \u001b[0m 0.6415  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-16.02   \u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 13.75   \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 67.7    \u001b[0m | \u001b[0m 0.8313  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-17.69   \u001b[0m | \u001b[0m 0.9672  \u001b[0m | \u001b[0m 0.2875  \u001b[0m | \u001b[0m 12.48   \u001b[0m | \u001b[0m 0.3242  \u001b[0m | \u001b[0m 62.21   \u001b[0m | \u001b[0m 0.8545  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-16.24   \u001b[0m | \u001b[0m 0.2981  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 12.81   \u001b[0m | \u001b[0m 0.8564  \u001b[0m | \u001b[0m 80.1    \u001b[0m | \u001b[0m 0.5558  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-16.49   \u001b[0m | \u001b[0m 0.423   \u001b[0m | \u001b[0m 0.1417  \u001b[0m | \u001b[0m 12.39   \u001b[0m | \u001b[0m 0.535   \u001b[0m | \u001b[0m 80.09   \u001b[0m | \u001b[0m 0.9526  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-14.46   \u001b[0m | \u001b[0m 0.3926  \u001b[0m | \u001b[0m 0.02235 \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 0.3537  \u001b[0m | \u001b[0m 138.8   \u001b[0m | \u001b[0m 0.6896  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-16.81   \u001b[0m | \u001b[0m 0.2111  \u001b[0m | \u001b[0m 0.05746 \u001b[0m | \u001b[0m 14.27   \u001b[0m | \u001b[0m 0.2316  \u001b[0m | \u001b[0m 62.71   \u001b[0m | \u001b[0m 0.9852  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-16.21   \u001b[0m | \u001b[0m 0.9014  \u001b[0m | \u001b[0m 0.2931  \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 0.4494  \u001b[0m | \u001b[0m 144.9   \u001b[0m | \u001b[0m 0.791   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-15.44   \u001b[0m | \u001b[0m 0.9906  \u001b[0m | \u001b[0m 0.06586 \u001b[0m | \u001b[0m 13.33   \u001b[0m | \u001b[0m 0.964   \u001b[0m | \u001b[0m 127.6   \u001b[0m | \u001b[0m 0.6695  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-15.52   \u001b[0m | \u001b[0m 0.9907  \u001b[0m | \u001b[0m 0.05812 \u001b[0m | \u001b[0m 12.15   \u001b[0m | \u001b[0m 0.2678  \u001b[0m | \u001b[0m 134.0   \u001b[0m | \u001b[0m 0.7596  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-16.26   \u001b[0m | \u001b[0m 0.8215  \u001b[0m | \u001b[0m 0.07625 \u001b[0m | \u001b[0m 14.37   \u001b[0m | \u001b[0m 0.7278  \u001b[0m | \u001b[0m 102.0   \u001b[0m | \u001b[0m 0.6855  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-16.12   \u001b[0m | \u001b[0m 0.2681  \u001b[0m | \u001b[0m 0.2175  \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 0.8024  \u001b[0m | \u001b[0m 102.2   \u001b[0m | \u001b[0m 0.6356  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-16.33   \u001b[0m | \u001b[0m 0.9937  \u001b[0m | \u001b[0m 0.09278 \u001b[0m | \u001b[0m 12.37   \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 0.9469  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-16.62   \u001b[0m | \u001b[0m 0.5369  \u001b[0m | \u001b[0m 0.188   \u001b[0m | \u001b[0m 14.03   \u001b[0m | \u001b[0m 0.4588  \u001b[0m | \u001b[0m 91.72   \u001b[0m | \u001b[0m 0.9059  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m 0.1961  \u001b[0m | \u001b[0m 0.05274 \u001b[0m | \u001b[0m 15.77   \u001b[0m | \u001b[0m 0.1051  \u001b[0m | \u001b[0m 81.28   \u001b[0m | \u001b[0m 0.8357  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-15.49   \u001b[0m | \u001b[0m 0.1785  \u001b[0m | \u001b[0m 0.2261  \u001b[0m | \u001b[0m 14.35   \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 91.78   \u001b[0m | \u001b[0m 0.823   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-16.33   \u001b[0m | \u001b[0m 0.2698  \u001b[0m | \u001b[0m 0.1753  \u001b[0m | \u001b[0m 14.09   \u001b[0m | \u001b[0m 0.5907  \u001b[0m | \u001b[0m 91.85   \u001b[0m | \u001b[0m 0.7     \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-17.03   \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.2353  \u001b[0m | \u001b[0m 13.6    \u001b[0m | \u001b[0m 0.1133  \u001b[0m | \u001b[0m 100.4   \u001b[0m | \u001b[0m 0.6245  \u001b[0m |\n",
      "| \u001b[95m 48      \u001b[0m | \u001b[95m-14.07   \u001b[0m | \u001b[95m 0.329   \u001b[0m | \u001b[95m 0.05789 \u001b[0m | \u001b[95m 13.61   \u001b[0m | \u001b[95m 0.1887  \u001b[0m | \u001b[95m 96.79   \u001b[0m | \u001b[95m 0.7164  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-14.63   \u001b[0m | \u001b[0m 0.2101  \u001b[0m | \u001b[0m 0.04499 \u001b[0m | \u001b[0m 15.81   \u001b[0m | \u001b[0m 0.2074  \u001b[0m | \u001b[0m 81.28   \u001b[0m | \u001b[0m 0.8441  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-15.25   \u001b[0m | \u001b[0m 0.2579  \u001b[0m | \u001b[0m 0.1457  \u001b[0m | \u001b[0m 13.91   \u001b[0m | \u001b[0m 0.1202  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.6108  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-15.75   \u001b[0m | \u001b[0m 0.1816  \u001b[0m | \u001b[0m 0.1234  \u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 0.1866  \u001b[0m | \u001b[0m 96.93   \u001b[0m | \u001b[0m 0.7351  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-14.36   \u001b[0m | \u001b[0m 0.1305  \u001b[0m | \u001b[0m 0.09845 \u001b[0m | \u001b[0m 12.22   \u001b[0m | \u001b[0m 0.6377  \u001b[0m | \u001b[0m 128.4   \u001b[0m | \u001b[0m 0.633   \u001b[0m |\n",
      "=================================================================================================\n",
      "{'target': -14.074444609298627, 'params': {'_lambda': 0.32902847452242395, 'learning_rate': 0.05788539762274639, 'max_depth': 13.612870162900137, 'min_child_weight': 0.18868310294529117, 'n_estimators': 96.79388709797425, 'subsample': 0.7164282712398647}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# # 하이퍼파라미터 정의\n",
    "# pbounds = {\n",
    "# 'max_depth': (11, 14), \n",
    "# 'learning_rate': (0.01, 0.3),\n",
    "# 'n_estimators': (50, 100),\n",
    "# 'min_child_weight': (0.1, 1),\n",
    "# 'subsample': (0.5, 1), \n",
    "# '_lambda' : (0.1,1),    \n",
    "# #'gamma': (0, 0.3),     \n",
    "# #'colsample_bytree' :(0.5, 1)\n",
    "# #'_alpha' : (0,1)           \n",
    "#                       }\n",
    "# 하이퍼파라미터 정의\n",
    "pbounds = {\n",
    "'max_depth': (12, 16), \n",
    "'learning_rate': (0.01, 0.3),\n",
    "'n_estimators': (50, 150),\n",
    "'min_child_weight': (0.1, 1),\n",
    "'subsample': (0.5, 1), \n",
    "'_lambda' : (0.1,1),    \n",
    "#'gamma': (0, 0.3),     \n",
    "#'colsample_bytree' :(0.5, 1)\n",
    "#'_alpha' : (0,1)           \n",
    "                      }\n",
    "\n",
    "# Bayesian optimization 객체 생성\n",
    "bo=BayesianOptimization(f=XGB, pbounds=pbounds, verbose=2, random_state=1 )    \n",
    "\n",
    "# 메소드를 이용해 최대화 과정 수행 (파라미터 넣고 목적함수 값 출력하고)\n",
    "bo.maximize(init_points=2, n_iter=50, acq='ei', xi=0.01)\n",
    "\n",
    "# 뽑힌 최적의 하이퍼파라미터 값 확인\n",
    "print(\"{}\\n\".format(bo.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd79a694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05788539762274639, max_delta_step=0, max_depth=13,\n",
       "             min_child_weight=0.18868310294529117, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=96, n_jobs=-1,\n",
       "             num_parallel_tree=1, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=0.32902847452242395, scale_pos_weight=1,\n",
       "             subsample=0.7164282712398647, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Train + Valid cross-validation을 거친, 최적의 하이퍼파라미터를 사용\n",
    "best_model = xgb.XGBRegressor(\n",
    "objective = 'reg:squarederror',\n",
    "max_depth=int(bo.max['params']['max_depth']),\n",
    "learning_rate=bo.max['params']['learning_rate'],\n",
    "n_estimators=int(bo.max['params']['n_estimators']),\n",
    "min_child_weight=bo.max['params']['min_child_weight'],\n",
    "subsample=bo.max['params']['subsample'],\n",
    "reg_lambda = bo.max['params']['_lambda'],    \n",
    "#gamma=bo.max['params']['gamma'],\n",
    "#colsample_bytree=bo.max['params']['colsample_bytree'],\n",
    "#reg_alpha = bo.max['params']['_alpha']\n",
    "n_jobs=-1\n",
    "                             )\n",
    "# 모델 훈련\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ec28fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': -14.074444609298627, 'params': {'_lambda': 0.32902847452242395, 'learning_rate': 0.05788539762274639, 'max_depth': 13.612870162900137, 'min_child_weight': 0.18868310294529117, 'n_estimators': 96.79388709797425, 'subsample': 0.7164282712398647}}\n",
      "\n",
      "-------- 훈련데이터 예측 --------------------------\n",
      "rmse : 0.4462145597382869\n",
      "mape : 0.7766231201214279%\n",
      "\n",
      "\n",
      "-------- 검증데이터 예측 --------------------------\n",
      "mape : 14.074444609298627%\n",
      "\n",
      "\n",
      "-------- 테스트데이터 예측 -------------------------\n",
      "rmse : 4.974654275823156\n",
      "mape : 11.274054423148476%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 값 확인\n",
    "print(\"{}\\n\".format(bo.max))\n",
    "\n",
    "# 훈련데이터 예측\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "print(\"-------- 훈련데이터 예측 --------------------------\")\n",
    "print(\"rmse : {}\".format(np.sqrt(mean_squared_error(y_train, y_train_pred))))\n",
    "print(\"mape : {}%\".format(mean_absolute_percentage_error(y_train, y_train_pred)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 검증데이터 예측\n",
    "print(\"-------- 검증데이터 예측 --------------------------\")\n",
    "print(\"mape : {}%\".format(-bo.max['target']))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 테스트데이터 예측\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"-------- 테스트데이터 예측 -------------------------\")\n",
    "print(\"rmse : {}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "print(\"mape : {}%\".format(mean_absolute_percentage_error(y_test, y_pred)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b340133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
