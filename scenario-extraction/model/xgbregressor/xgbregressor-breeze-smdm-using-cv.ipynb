{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1727, 191\n",
    "train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/1727-nonsquare-train-from-1918-nonsquare-spmm-over-3s.csv')\n",
    "test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/191-nonsquare-test-from-1918-nonsquare-spmm-over-3s.csv')\n",
    "\n",
    "# # 1918, 350\n",
    "# train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/1918-nonsquare-train-from-2268-spmm-over-3s.csv')\n",
    "# test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/350-square-test-from-2268-spmm-over-3s.csv')\n",
    "\n",
    "# # 1164, 129\n",
    "# train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/1164-train-from-1293-spmm-over-3s.csv')\n",
    "# test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/129-test-from-1293-spmm-over-3s.csv')\n",
    "\n",
    "# 2268, 226\n",
    "# train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/2042-train-from-2268-spmm-over-3s.csv')\n",
    "# test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/d-optimal-of-spmm/train-test-csv/226-test-from-2268-spmm-over-3s.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + Valid\n",
    "X_train = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc','lr*lc*rc','ld*rd','lr*rc*ld*rd','lr*lc*rc*ld*rd']] \n",
    "y_train = train['bz_smdm']\n",
    "\n",
    "# Test\n",
    "X_test = test[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc','lr*lc*rc','ld*rd','lr*rc*ld*rd','lr*lc*rc*ld*rd']] \n",
    "y_test = test['bz_smdm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Metric\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "def custom_scoring(real, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(real, pred))\n",
    "    r2 = r2_score(real, pred)\n",
    "    mape = mean_absolute_percentage_error(real, pred)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 탐색 대상 함수 (XGBRegressor)\n",
    "def XGB(\n",
    "max_depth,\n",
    "learning_rate, \n",
    "n_estimators, \n",
    "min_child_weight, \n",
    "subsample,\n",
    "_lambda,\n",
    "#gamma ,\n",
    "#colsample_bytree, \n",
    "#_alpha,\n",
    "silent=True, \n",
    "n_jobs=-1):\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = xgb.XGBRegressor( \n",
    "objective = 'reg:squarederror',\n",
    "max_depth=int(max_depth),\n",
    "learning_rate=learning_rate,\n",
    "n_estimators=int(n_estimators),\n",
    "min_child_weight=min_child_weight,\n",
    "subsample=subsample,\n",
    "reg_lambda=_lambda,        \n",
    "#gamma=gamma,\n",
    "#colsample_bytree=colsample_bytree, \n",
    "#reg_alpha=_alpha\n",
    "n_jobs=n_jobs        \n",
    "                              )\n",
    "    \n",
    "    # bayesian optimization을 통해 파라미터를 받아\n",
    "    # Train을 Train + Validation으로 나눠 cross-validation 성능 확인\n",
    "    kfold = KFold(n_splits=9, shuffle = True, random_state=0)\n",
    "\n",
    "    # cross-validation 평균 성능 성능 확인\n",
    "    score = cross_val_score(model,\n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=kfold,\n",
    "                            scoring=make_scorer(custom_scoring,greater_is_better=False),\n",
    "                            n_jobs=-1\n",
    "                           ).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  _lambda  | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-28.98   \u001b[0m | \u001b[0m 0.4753  \u001b[0m | \u001b[0m 0.1469  \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 0.3721  \u001b[0m | \u001b[0m 64.68   \u001b[0m | \u001b[0m 0.1831  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-14.33   \u001b[0m | \u001b[95m 0.2676  \u001b[0m | \u001b[95m 0.07566 \u001b[0m | \u001b[95m 13.59   \u001b[0m | \u001b[95m 0.5849  \u001b[0m | \u001b[95m 91.92   \u001b[0m | \u001b[95m 0.7167  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-14.46   \u001b[0m | \u001b[0m 0.2233  \u001b[0m | \u001b[0m 0.07657 \u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 0.4265  \u001b[0m | \u001b[0m 91.26   \u001b[0m | \u001b[0m 0.6252  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-143.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 107.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-44.69   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 79.65   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-107.1   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.07   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 52.34   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-16.44   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 70.04   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-24.92   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-82.21   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 140.9   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-69.14   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 89.97   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-40.1    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 92.41   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-15.96   \u001b[0m | \u001b[0m 0.816   \u001b[0m | \u001b[0m 0.1812  \u001b[0m | \u001b[0m 14.59   \u001b[0m | \u001b[0m 0.196   \u001b[0m | \u001b[0m 68.16   \u001b[0m | \u001b[0m 0.7134  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-15.58   \u001b[0m | \u001b[0m 0.8043  \u001b[0m | \u001b[0m 0.1343  \u001b[0m | \u001b[0m 13.55   \u001b[0m | \u001b[0m 0.4178  \u001b[0m | \u001b[0m 70.35   \u001b[0m | \u001b[0m 0.6961  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-23.13   \u001b[0m | \u001b[0m 0.1906  \u001b[0m | \u001b[0m 0.1447  \u001b[0m | \u001b[0m 14.69   \u001b[0m | \u001b[0m 0.9953  \u001b[0m | \u001b[0m 69.65   \u001b[0m | \u001b[0m 0.2734  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-15.59   \u001b[0m | \u001b[0m 0.9504  \u001b[0m | \u001b[0m 0.037   \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 0.8969  \u001b[0m | \u001b[0m 68.3    \u001b[0m | \u001b[0m 0.9226  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-47.69   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.4    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 73.62   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-15.52   \u001b[0m | \u001b[0m 0.9784  \u001b[0m | \u001b[0m 0.1339  \u001b[0m | \u001b[0m 15.92   \u001b[0m | \u001b[0m 0.9839  \u001b[0m | \u001b[0m 65.26   \u001b[0m | \u001b[0m 0.6335  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-18.76   \u001b[0m | \u001b[0m 0.8853  \u001b[0m | \u001b[0m 0.1899  \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 0.3112  \u001b[0m | \u001b[0m 61.99   \u001b[0m | \u001b[0m 0.419   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-15.69   \u001b[0m | \u001b[0m 0.1787  \u001b[0m | \u001b[0m 0.0995  \u001b[0m | \u001b[0m 15.36   \u001b[0m | \u001b[0m 0.123   \u001b[0m | \u001b[0m 64.24   \u001b[0m | \u001b[0m 0.7994  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-18.92   \u001b[0m | \u001b[0m 0.2306  \u001b[0m | \u001b[0m 0.05705 \u001b[0m | \u001b[0m 15.99   \u001b[0m | \u001b[0m 0.1549  \u001b[0m | \u001b[0m 149.9   \u001b[0m | \u001b[0m 0.2362  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-30.44   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 125.2   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-112.4   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 69.74   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-15.79   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.09177 \u001b[0m | \u001b[0m 14.43   \u001b[0m | \u001b[0m 0.3736  \u001b[0m | \u001b[0m 69.93   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-15.13   \u001b[0m | \u001b[0m 0.9793  \u001b[0m | \u001b[0m 0.09563 \u001b[0m | \u001b[0m 13.19   \u001b[0m | \u001b[0m 0.9368  \u001b[0m | \u001b[0m 67.46   \u001b[0m | \u001b[0m 0.7991  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-15.57   \u001b[0m | \u001b[0m 0.8074  \u001b[0m | \u001b[0m 0.0665  \u001b[0m | \u001b[0m 14.82   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 66.06   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-16.76   \u001b[0m | \u001b[0m 0.9216  \u001b[0m | \u001b[0m 0.1673  \u001b[0m | \u001b[0m 14.27   \u001b[0m | \u001b[0m 0.9464  \u001b[0m | \u001b[0m 71.29   \u001b[0m | \u001b[0m 0.5415  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m 0.9405  \u001b[0m | \u001b[0m 0.1615  \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 0.441   \u001b[0m | \u001b[0m 67.77   \u001b[0m | \u001b[0m 0.9544  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-16.36   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 63.58   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-59.41   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 14.47   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 65.03   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-16.15   \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 0.1824  \u001b[0m | \u001b[0m 15.8    \u001b[0m | \u001b[0m 0.5089  \u001b[0m | \u001b[0m 63.74   \u001b[0m | \u001b[0m 0.9626  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-51.6    \u001b[0m | \u001b[0m 0.3136  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 65.88   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-16.94   \u001b[0m | \u001b[0m 0.2712  \u001b[0m | \u001b[0m 0.05449 \u001b[0m | \u001b[0m 14.81   \u001b[0m | \u001b[0m 0.1425  \u001b[0m | \u001b[0m 62.99   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-16.4    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 15.53   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 68.75   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-48.92   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 13.8    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 70.44   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-23.1    \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.1427  \u001b[0m | \u001b[0m 14.42   \u001b[0m | \u001b[0m 0.1046  \u001b[0m | \u001b[0m 70.28   \u001b[0m | \u001b[0m 0.2376  \u001b[0m |\n",
      "| \u001b[95m 36      \u001b[0m | \u001b[95m-13.98   \u001b[0m | \u001b[95m 0.7075  \u001b[0m | \u001b[95m 0.04668 \u001b[0m | \u001b[95m 15.32   \u001b[0m | \u001b[95m 0.2085  \u001b[0m | \u001b[95m 69.24   \u001b[0m | \u001b[95m 0.6921  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-51.01   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 14.39   \u001b[0m | \u001b[0m 0.2132  \u001b[0m | \u001b[0m 66.98   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-15.43   \u001b[0m | \u001b[0m 0.8243  \u001b[0m | \u001b[0m 0.1092  \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 0.4293  \u001b[0m | \u001b[0m 68.89   \u001b[0m | \u001b[0m 0.6862  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-36.8    \u001b[0m | \u001b[0m 0.7786  \u001b[0m | \u001b[0m 0.154   \u001b[0m | \u001b[0m 15.34   \u001b[0m | \u001b[0m 0.3584  \u001b[0m | \u001b[0m 68.5    \u001b[0m | \u001b[0m 0.1382  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-15.59   \u001b[0m | \u001b[0m 0.9788  \u001b[0m | \u001b[0m 0.1537  \u001b[0m | \u001b[0m 15.12   \u001b[0m | \u001b[0m 0.1457  \u001b[0m | \u001b[0m 68.82   \u001b[0m | \u001b[0m 0.9751  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-17.16   \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 13.81   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 71.18   \u001b[0m | \u001b[0m 0.5822  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-16.08   \u001b[0m | \u001b[0m 0.2278  \u001b[0m | \u001b[0m 0.1709  \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 0.1542  \u001b[0m | \u001b[0m 68.92   \u001b[0m | \u001b[0m 0.8447  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-16.29   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.92   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 68.07   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-15.42   \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 67.33   \u001b[0m | \u001b[0m 0.5734  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-53.1    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.18   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 62.69   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-17.68   \u001b[0m | \u001b[0m 0.1147  \u001b[0m | \u001b[0m 0.1227  \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 0.1911  \u001b[0m | \u001b[0m 63.52   \u001b[0m | \u001b[0m 0.978   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-50.2    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 12.37   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 67.54   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-15.34   \u001b[0m | \u001b[0m 0.7254  \u001b[0m | \u001b[0m 0.1238  \u001b[0m | \u001b[0m 13.58   \u001b[0m | \u001b[0m 0.7727  \u001b[0m | \u001b[0m 68.23   \u001b[0m | \u001b[0m 0.5897  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-20.43   \u001b[0m | \u001b[0m 0.5612  \u001b[0m | \u001b[0m 0.04016 \u001b[0m | \u001b[0m 12.23   \u001b[0m | \u001b[0m 0.4576  \u001b[0m | \u001b[0m 67.4    \u001b[0m | \u001b[0m 0.1222  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-16.48   \u001b[0m | \u001b[0m 0.712   \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 14.93   \u001b[0m | \u001b[0m 0.1744  \u001b[0m | \u001b[0m 63.83   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-15.76   \u001b[0m | \u001b[0m 0.752   \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 0.7515  \u001b[0m | \u001b[0m 69.64   \u001b[0m | \u001b[0m 0.8295  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-61.24   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 66.89   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "=================================================================================================\n",
      "{'target': -13.979119640663335, 'params': {'_lambda': 0.7074715186887154, 'learning_rate': 0.04667755307822825, 'max_depth': 15.320934743535151, 'min_child_weight': 0.20847604260697317, 'n_estimators': 69.23980364616008, 'subsample': 0.6921489318264444}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# # 하이퍼파라미터 정의\n",
    "# pbounds = {\n",
    "# 'max_depth': (12, 16), \n",
    "# 'learning_rate': (0.01, 0.3),\n",
    "# 'n_estimators': (50, 100),\n",
    "# 'min_child_weight': (0.1, 1),\n",
    "# 'subsample': (0.5, 1), \n",
    "# '_lambda' : (0.1,1),    \n",
    "# #'gamma': (0, 0.3),     \n",
    "# #'colsample_bytree' :(0.5, 1)\n",
    "# #'_alpha' : (0,1)           \n",
    "#                       }\n",
    "\n",
    "# 하이퍼파라미터 정의\n",
    "pbounds = {\n",
    "'max_depth': (12, 16), \n",
    "'learning_rate': (0.01, 0.2),\n",
    "'n_estimators': (50, 150),\n",
    "'min_child_weight': (0.1, 1),\n",
    "'subsample': (0.1, 1), \n",
    "'_lambda' : (0.1,1),    \n",
    "#'gamma': (0, 0.3),     \n",
    "#'colsample_bytree' :(0.5, 1)\n",
    "#'_alpha' : (0,1)           \n",
    "                      }\n",
    "\n",
    "# Bayesian optimization 객체 생성\n",
    "bo=BayesianOptimization(f=XGB, pbounds=pbounds, verbose=2, random_state=1 )    \n",
    "\n",
    "# 메소드를 이용해 최대화 과정 수행 (파라미터 넣고 목적함수 값 출력하고)\n",
    "bo.maximize(init_points=2, n_iter=50, acq='ei', xi=0.01)\n",
    "\n",
    "# 뽑힌 최적의 하이퍼파라미터 값 확인\n",
    "print(\"{}\\n\".format(bo.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(learning_rate=0.04667755307822825, max_depth=15,\n",
       "             min_child_weight=0.20847604260697317, n_estimators=69, n_jobs=-1,\n",
       "             objective='reg:squarederror', reg_lambda=0.7074715186887154,\n",
       "             subsample=0.6921489318264444)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Train + Valid cross-validation을 거친, 최적의 하이퍼파라미터를 사용\n",
    "best_model = xgb.XGBRegressor(\n",
    "objective = 'reg:squarederror',\n",
    "max_depth=int(bo.max['params']['max_depth']),\n",
    "learning_rate=bo.max['params']['learning_rate'],\n",
    "n_estimators=int(bo.max['params']['n_estimators']),\n",
    "min_child_weight=bo.max['params']['min_child_weight'],\n",
    "subsample=bo.max['params']['subsample'],\n",
    "reg_lambda = bo.max['params']['_lambda'],    \n",
    "#gamma=bo.max['params']['gamma'],\n",
    "#colsample_bytree=bo.max['params']['colsample_bytree'],\n",
    "#reg_alpha = bo.max['params']['_alpha']\n",
    "n_jobs=-1\n",
    "                             )\n",
    "# 모델 훈련\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': -13.979119640663335, 'params': {'_lambda': 0.7074715186887154, 'learning_rate': 0.04667755307822825, 'max_depth': 15.320934743535151, 'min_child_weight': 0.20847604260697317, 'n_estimators': 69.23980364616008, 'subsample': 0.6921489318264444}}\n",
      "\n",
      "-------- 훈련데이터 예측 --------------------------\n",
      "rmse : 72211.57391952482\n",
      "mape : 4.705451450925878%\n",
      "\n",
      "\n",
      "-------- 검증데이터 예측 --------------------------\n",
      "mape : 13.979119640663335%\n",
      "\n",
      "\n",
      "-------- 테스트데이터 예측 -------------------------\n",
      "rmse : 169378.27090805894\n",
      "mape : 13.253508500978409%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 값 확인\n",
    "print(\"{}\\n\".format(bo.max))\n",
    "\n",
    "# 훈련데이터 예측\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "print(\"-------- 훈련데이터 예측 --------------------------\")\n",
    "print(\"rmse : {}\".format(np.sqrt(mean_squared_error(y_train, y_train_pred))))\n",
    "print(\"mape : {}%\".format(mean_absolute_percentage_error(y_train, y_train_pred)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 검증데이터 예측\n",
    "print(\"-------- 검증데이터 예측 --------------------------\")\n",
    "print(\"mape : {}%\".format(-bo.max['target']))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 테스트데이터 예측\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"-------- 테스트데이터 예측 -------------------------\")\n",
    "print(\"rmse : {}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "print(\"mape : {}%\".format(mean_absolute_percentage_error(y_test, y_pred)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mape_list = {}\n",
    "# # 예측값, 실제값을 확인하며 mape 계산 후 mape_list에 삽입 \n",
    "# for idx,value in enumerate(y_test):\n",
    "#     mape_temp = {}\n",
    "#     predicate = int(y_pred[idx])\n",
    "#     mape = abs((value - predicate) / value) * 100\n",
    "#     mape_temp['pred'] = predicate\n",
    "#     mape_temp['real'] = value\n",
    "#     mape_temp['mape'] = mape\n",
    "#     mape_list[idx] = mape_temp\n",
    "# mape_list_sort = sorted(mape_list.values(), key=lambda x:(x['mape']), reverse=True)\n",
    "# mape_list_sort  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
